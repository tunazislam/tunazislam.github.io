---
title: "Who Gets Which Climate Message? Auditing Age and Gender Bias in LLM-Generated Microtargeted Communication"
collection: publications
permalink: /publications/bias-llms-generated-climate-microtarget
venue: "Preprint 2025"
citation: '<b>Tunazzina Islam</b>. Preprint 2025.'

---
<!--- [[arXiv]](https://arxiv.org/pdf/2404.10259.pdf) -->

## Abstract
Large language models (LLMs) are increasingly capable of generating personalized, persuasive text at scale, raising new questions about bias and fairness in automated communication. This paper presents the first systematic analysis of how LLMs might behave if used for microtargeted climate messaging. We construct a controlled evaluation framework using three leading models—GPT-4o, Llama-3.3, and Mistral-Large-2.1—across two settings: **Standalone Generation**, which isolates intrinsic bias, and **Context-Rich Generation**, which adds thematic and regional context to emulate realistic targeting. We assess outputs along three dimensions: *lexical content*, *language style*, and *persuasive framing*.
Results show consistent gender and age asymmetries across models: male- and youth-targeted messages emphasize *agency*, *innovation*, and *energy*, while female- and senior-targeted ones stress *warmth*, *care*, and *tradition*. Contextual prompts amplify these effects, and persuasion scores are significantly higher for messages tailored to younger or male audiences. Our findings reveal how demographic stereotypes can surface even in hypothetical LLM-driven outreach, underscoring the need for bias-aware generation pipelines and transparent auditing frameworks for socially sensitive applications like climate communication.

